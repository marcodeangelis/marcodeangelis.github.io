<!DOCTYPE html>
<html>
  <head>
    <title>My biblio</title>
  </head>
  <body>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">Advanced Line Sampling for efficient robust reliability analysis</h3>
          <h4 style="color:gray;"> De Angelis, M.,  Patelli, E.,  Beer, M., </h4>
          <h4 style="color:blue;">2015</h4>
          <h4 style="color:green;">Structural Safety</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1016/j.strusafe.2014.10.002">10.1016/j.strusafe.2014.10.002</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: A numerical strategy for the efficient estimation of set-valued failure probabilities, coupling Monte Carlo with optimization methods, is presented in this paper. The notion of uncertainty is generalized to include both aleatory and epistemic uncertainties, allowing to capture gaps of knowledge and scarcity of data. The proposed formulation of the generalized uncertainty model allows for sets of probability distribution functions, also known as credal sets, and sets of bounded variables. The developed Advanced Line Sampling method is combined with the generalized uncertainty model, in order to both speed up the reliability analysis, and provide a better estimate for the lower and upper bounds of the failure probability. The proposed strategy knocks down the computational barrier of computing interval failure probabilities, and reduces the cost of a robust reliability analysis by many orders of magnitude. The efficiency and applicability of the developed method is demonstrated via numerical examples. The solution strategy is integrated into the open-source software for uncertainty quantification and risk analysis O. penC. ossan, allowing its application on large-scale engineering problems as well as broadening its spectrum of applications. © 2014 Elsevier Ltd.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84918586942&amp;doi=10.1016%2fj.strusafe.2014.10.002&amp;partnerID=40&amp;md5=b709c74245d37d09bedd9c10e63f327f">[scopus]</a> | <a href="https://studylibit.com/doc/1586954/sui-confini-della-probabilit%C3%A0-1">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">Uncertainty management in multidisciplinary design of critical safety systems</h3>
          <h4 style="color:gray;"> Patelli, E.,  Alvarez, D.A.,  Broggi, M.,  De Angelis, M., </h4>
          <h4 style="color:blue;">2015</h4>
          <h4 style="color:green;">Journal of Aerospace Information Systems</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.2514/1.I010273">10.2514/1.I010273</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: Managing the uncertainty in multidisciplinary design of safety-critical systems requires not only the availability of a single approach or methodology to deal with uncertainty but aset of different strategies and scalable computational tools (that is, by making use of the computational power of a cluster and grid computing). The availability of multiple tools and approaches for dealing with uncertainties allows cross validation of the results and increases the confidence in the performed analysis. This paper presents a unified theory and an integrated and open general-purpose computational framework to deal with scarce data, and aleatory and epistemic uncertainties. It allows solving of the different tasks necessary to manage the uncertainty, such as uncertainty characterization, sensitivity analysis, uncertainty quantification, and robust design. The proposed computational framework is generally applicable to solve different problems in different fields and be numerically efficient and scalable, allowing for a significant reductionof the computational time required for uncertainty management and robust design. The applicabilityof the proposed approach is demonstrated by solving a multidisciplinary design of a critical system proposed by NASA Langley Research Center in the multidisciplinary uncertainty quantification challenge problem. Copyright © 2014 by University of Liverpool (U.K.) and Universidad NacionaldeColombia Sede Manizales(Colombia).</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84922432517&amp;doi=10.2514%2f1.I010273&amp;partnerID=40&amp;md5=692dfe1597398e379caaad3735476d61">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">Forced Monte Carlo Simulation Strategy for the Design of Maintenance Plans with Multiple Inspections</h3>
          <h4 style="color:gray;"> De Angelis, M.,  Patelli, E.,  Beer, M., </h4>
          <h4 style="color:blue;">2017</h4>
          <h4 style="color:green;">ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems, Part A: Civil Engineering</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1061/AJRUA6.0000868">10.1061/AJRUA6.0000868</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: A maintenance problem can be regarded as an optimization task, where the solution is a trade-off between the costs associated with inspection and repair activities and the benefits related to the faultless operation of the infrastructure. The optimization aims at minimizing the total cost while tuning some parameters, such as the number, time, and quality of inspections. Due to the unavoidable uncertainties, the expected cost of maintenance and failure can only be estimated by assessing the reliability of the system. The problem is, therefore, formulated as a time-variant reliability-based optimization, where both objective and constraint functions require the assessment of reliability with time. This paper proposes an efficient general numerical technique to solve this problem by means of just one single reliability analysis, while explicitly taking the diverse forms of uncertainty into account. The technique is generally applicable to any problem where the ageing or damage propagation process is known by means of input-output relationships, which apply to a great number of the cases. This technique exploits a Monte Carlo strategy derived from the concept of forced simulation, which significantly increases the efficiency of computing the optimal solution. The efficiency and accuracy of the proposed approach is shown by means of an example involving a fatigue-prone weld in a bridge girder. © 2016 American Society of Civil Engineers.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045318116&amp;doi=10.1061%2fAJRUA6.0000868&amp;partnerID=40&amp;md5=09041ea79bbbc85af3d3071d9ae91736">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">Utilising database-driven interactive software to enhance independent home-study in a flipped classroom setting: going beyond visualising engineering concepts to ensuring formative assessment</h3>
          <h4 style="color:gray;"> Comerford, L.,  Mannis, A.,  De Angelis, M.,  Kougioumtzoglou, I.A.,  Beer, M., </h4>
          <h4 style="color:blue;">2018</h4>
          <h4 style="color:green;">European Journal of Engineering Education</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1080/03043797.2017.1293617">10.1080/03043797.2017.1293617</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: The concept of formative assessment is considered by many to play an important role in enhancing teaching in higher engineering education. In this paper, the concept of the flipped classroom as part of a blended learning curriculum is highlighted as an ideal medium through which formative assessment practices arise. Whilst the advantages of greater interaction between students and lecturers in classes are numerous, there are often clear disadvantages associated with the independent home-study component that complements timetabled sessions in a flipped classroom setting, specifically, the popular method of replacing traditional classroom teaching with video lectures. This leads to a clear lack of assurances that the cited benefits of a flipped classroom approach are echoed in the home-study arena. Over the past three years, the authors have sought to address identified deficiencies in this area of blended learning through the development of database-driven e-learning software with the capability of introducing formative assessment practices to independent home-study. This paper maps out aspects of two specific evolving practices at separate institutions, from which guiding principles of incorporating formative assessment aspects into e-learning software are identified and highlighted in the context of independent home-study as part of a flipped classroom approach. © 2017 SEFI.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014757882&amp;doi=10.1080%2f03043797.2017.1293617&amp;partnerID=40&amp;md5=66da5453b3844dab553579ea98ccafe8">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">Frequentist history matching with Interval Predictor Models</h3>
          <h4 style="color:gray;"> Sadeghi, J.,  De Angelis, M.,  Patelli, E., </h4>
          <h4 style="color:blue;">2018</h4>
          <h4 style="color:green;">Applied Mathematical Modelling</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1016/j.apm.2018.04.003">10.1016/j.apm.2018.04.003</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In this paper a novel approach is presented for history matching models without making assumptions about the measurement error. Interval Predictor Models are used to robustly model the observed data and hence a novel figure of merit is proposed to quantify the quality of matches in a frequentist probabilistic framework. The proposed method yields bounds on the p-values from frequentist inference. The method is first applied to a simple example and then to a realistic case study (the Imperial College Fault Model) in order to evaluate its applicability and efficacy. When there is no modelling error the method identifies a feasible region for the matched parameters, which for our test case contained the truth case. When attempting to match one model to data from a different model, a region close to the truth case was identified. The effect of increasing the number of data points on the history matching is also discussed. © 2018 Elsevier Inc.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046141954&amp;doi=10.1016%2fj.apm.2018.04.003&amp;partnerID=40&amp;md5=00a44795d935da1c82103aa99fc19c7b">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">Reliability-based optimal design of nonlinear viscous dampers for the seismic protection of structural systems</h3>
          <h4 style="color:gray;"> Altieri, D.,  Tubaldi, E.,  De Angelis, M.,  Patelli, E.,  Dall’Asta, A., </h4>
          <h4 style="color:blue;">2018</h4>
          <h4 style="color:green;">Bulletin of Earthquake Engineering</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1007/s10518-017-0233-4">10.1007/s10518-017-0233-4</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: Viscous dampers are widely employed for enhancing the seismic performance of structural systems, and their design is often carried out using simplified approaches to account for the uncertainty in the seismic input. This paper introduces a novel and rigorous approach that allows to explicitly consider the variability of the intensity and characteristics of the seismic input in designing the optimal viscous constant and velocity exponent of the dampers based on performance-based criteria. The optimal solution permits controlling the probability of structural failure, while minimizing the damper cost, related to the sum of the damper forces. The solution to the optimization problem is efficiently sought via the constrained optimization by linear approximation (COBYLA) method, while Subset simulation together with auxiliary response method are employed for the performance assessment at each iteration of the optimization process. A 3-storey steel moment-resisting building frame is considered to illustrate the application of the proposed design methodology and to evaluate and compare the performances that can be achieved with different damper nonlinearity levels. Comparisons are also made with the results obtained by applying simplifying approaches, often employed in design practice, as those aiming to minimize the sum of the viscous damping constant and/or considering a single hazard level for the performance assessment. © Springer Science+Business Media B.V. 2017.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029483606&amp;doi=10.1007%2fs10518-017-0233-4&amp;partnerID=40&amp;md5=8133008fca432803badb7b292b7f0ef5">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Journal article</p>
          <h3 style="text-align:center;">On the robust estimation of small failure probabilities for strong non-linear models</h3>
          <h4 style="color:gray;"> Faes, M.,  Sadeghi, J.,  Broggi, M.,  Angelis, M.,  Patelli, E,  Beer, M.,  Moens, D., </h4>
          <h4 style="color:blue;">2019</h4>
          <h4 style="color:green;">ASCE-ASME Journal of Risk and Uncertainty in Engineering Systems Part B: Mechanical Engineering</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: Structural reliability methods are nowadays a cornerstone for the design of robustly performing structures, thanks to advancements in modeling and simulation tools. Monte-Carlo based simulation tools have been shown to provide the necessary accuracy and flexibility. While standard Monte-Carlo estimation of the probability of failure is not hindered in its applicability by approximations or limiting assumptions, it becomes computationally unfea-sible when small failure probability needs to be estimated, especially when the underlying numerical model evaluation is time consuming. In this case, variance reduction techniques are commonly employed, allowing for the estimation of small failure probabilities with a reduced number of samples and model calls. As a competing approach to variance reduction techniques, surrogate models can be used to substitute the computation-ally expensive model and performance function with an easy to evaluate numerical function calibrated through a supervised learning procedure. Both these tools can provide accurate results for structural application. However, particular care should be taken into account when the reliability problems deal with high dimensional or strongly non-linear structural performances. In this work, we compare the performance of the most recent state-of-the-art advance Monte-Carlo techniques and surrogate models when applied to strongly non-linear performance functions. This will provide the analysts with an insight to the issues that could arise in these challenging problems and help to decide with confidence on which tool to select in order to achieve accurate estimation of the failure probabilities within feasible times with their available computational capabilities.</p>
          <p style="text-align:right;"><a href="">[scopus]</a> | <a href="https://www.researchgate.net/profile/Matthias_Faes2/publication/330765220_On_the_robust_estimation_of_small_failure_probabilities_for_strong_non-linear_models/links/5c535d46299bf12be3f1041b/On-the-robust-estimation-of-small-failure-probabilities-for-strong-non-linear-models.pdf">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">On robust maintenance scheduling of fatigue-prone structural systems considering imprecise probability</h3>
          <h4 style="color:gray;"> Patelli, E.,  Valdebenito, M.A.,  De Angelis, M., </h4>
          <h4 style="color:blue;">2013</h4>
          <h4 style="color:green;">Chemical Engineering Transactions</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.3303/CET1333181">10.3303/CET1333181</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: Crack propagation in metallic mechanical components subject to cyclic loading may lead to loss of serviceability or even collapse. Often, these undesirable events may be prevented by performing appropriate maintenance activities. Nonetheless, the scheduling of these activities is highly involved due to the inherent uncertainty associated with crack propagation. In this contribution, a framework for optimal scheduling of maintenance activities within the theory of imprecise probabilities is presented. In this manner, effects of uncertainty are considered in a rational way. The proposed approach is implemented in a general purpose software for stochastic analysis. A numerical example demonstrates the applicability of the proposed framework as well as the importance of considering the effects of uncertainty. Copyright © 2013, AIDIC Servizi S.r.l.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883769004&amp;doi=10.3303%2fCET1333181&amp;partnerID=40&amp;md5=d637dd9be01370e0ef97b8f3274fa984">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">PhD thesis</p>
          <h3 style="text-align:center;">Efficient random set uncertainty quantification by means of advanced sampling techniques</h3>
          <h4 style="color:gray;"> De Angelis, Marco, </h4>
          <h4 style="color:blue;">2015</h4>
          <h4 style="color:green;"></h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In this dissertation, Random Sets and Advanced Sampling techniques are combined forgeneral and efficient uncertainty quantification. Random Sets extend the traditional probabilistic framework, as they also comprise imprecision to account for scarce data,lack of knowledge, vagueness, subjectivity, etc. The general attitude of Random Setsto include different kinds of uncertainty is paid to a very high computational price. In fact, Random Sets requires a min-max convolution for each sample picked by theMonte Carlo method. The speed of the min-max convolution can be sensibly increasedwhen the system response relationship is known in analytical form. However, in ageneral multidisciplinary design context, the system response is very often treated asa “black box”; thus, the convolution requires the adoption of evolutionary or stochastic algorithms, which need to be deployed for each Monte Carlo sample. Therefore, theavailability of very efficient sampling techniques is paramount to allow Random Sets tobe applied to engineering problems.In this dissertation, Advanced Line Sampling methods have been generalised andextended to include Random Sets. Advanced Sampling techniques make the estimationof quantiles on relevant probabilities extremely efficient, by requiring significantly fewer numbers of samples compared to standard Monte Carlo methods. In particular, theLine Sampling method has been enhanced to link well to the Random Set representa-tion. These developments comprise line search, line selection, direction adaptation, anddata buffering. The enhanced efficiency of Line Sampling is demonstrated by meansof numerical and large scale finite element examples. With the enhanced algorithm,the connection between Line Sampling and the generalised uncertainty model has beenpossible, both in a Double Loop and in a Random Set approach. The presented compu-tational strategies have been implemented in the open source general purpose softwarefor uncertainty quantification,OpenCossan.The general reach of the proposed strategy is demonstrated by means of applicationsto structural reliability of a finite element model, to preventive maintenance, and to the NASA Langley multidisciplinary uncertainty quantification challenge.</p>
          <p style="text-align:right;"><a href="https://core.ac.uk/download/pdf/80774362.pdf">[scopus]</a> | <a href="https://core.ac.uk/download/pdf/80774362.pdf">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Uncertainty estimation of road-dust emissions via interval statistics</h3>
          <h4 style="color:gray;"> De-Angelis, M.,  Ricciardi, V.,  Dalmau, E., </h4>
          <h4 style="color:blue;">2018</h4>
          <h4 style="color:green;">Journal of Physics: Conference Series</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1088/1742-6596/1065/21/212023">10.1088/1742-6596/1065/21/212023</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: Particulate matter, a.k.a. particle pollution, is a complex mixture of small particles and liquid droplets that are present in the air. Once inhaled, these particles can affect the heart and lungs and cause serious health problems. A recent study, based on geographically referenced datasets of pollutant emissions has shown that non-exhaust related pollution is at present dominant and increasing. Emissions from paved roads are poorly estimated due to the lack of knowledge about the resuspension process. Recent literature works have attempted to provide a reliable framework for the estimation of emission factors. Estimations are obtained by linear regression with a single-valued discriminant for the acceptance/rejection of the experimental dataset based on the evaluation of the r-squared coefficient. In this paper, we explore alternative methods to evaluate the &#34;quality&#34; of the data and consequently discriminate whether a given sample can be accepted to provide estimation of the emission factors. Uncertainties are characterised both in the data and in the statistical model. Measurements are expressed with interval-valued datapoints to include the experiment precision directly within the estimation process. Alternative fitting techniques that avoid the use a single-valued discriminant are also explored for an inclusive estimation of the emission factors. © 2018 Institute of Physics Publishing. All rights reserved.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057480332&amp;doi=10.1088%2f1742-6596%2f1065%2f21%2f212023&amp;partnerID=40&amp;md5=5d5195b14f9c88baa426098869c7cb4e">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Low-Cost Battery Monitoring by Converter-Based Electrochemical Impedance Spectroscopy</h3>
          <h4 style="color:gray;"> Ferrero, R.,  Wu, C.,  Carboni, A.,  Toscani, S.,  De Angelis, M.,  George-Williams, H.,  Patelli, E.,  Pegoraro, P.A., </h4>
          <h4 style="color:blue;">2017</h4>
          <h4 style="color:green;">AMPS 2017 - IEEE International Workshop on Applied Measurements for Power Systems, Proceedings</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1109/AMPS.2017.8078334">10.1109/AMPS.2017.8078334</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: The use of batteries and other electrochemical devices in modern power systems is rapidly increasing, with stricter requirements in terms of cost, efficiency and reliability. Innovative monitoring solutions are therefore urged to allow a successful development of a wide range of emerging applications, including electric vehicles and large-scale energy storage to support renewable energy generation. Presently, a huge gap still exists between the accurate and sophisticated monitoring techniques commonly employed in laboratory tests, on the one hand, and the simple and rough solutions available in most commercial applications, on the other hand. The objective of this paper is therefore to contribute to the development of low-cost but accurate solutions for commercial battery condition monitoring, by proposing an embedded system that combines real-time digital signal processing with the high computational power and user friendly interface of a modern computer, at a cost comparable to a simple micro-controller. In more detail, the paper focuses on electrochemical impedance spectroscopy on a battery performed by a DC-DC power converter, and it explains how the proposed low-cost off-the-shelf hardware can control the converter, acquire the measurement signals, accurately process them in the time and frequency domains, and estimate the result uncertainty in real-time, which is necessary to promptly and reliably detect any variation in the battery condition. © 2017 IEEE.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040088033&amp;doi=10.1109%2fAMPS.2017.8078334&amp;partnerID=40&amp;md5=ee78b2b6eb13b17cec006dcd411fa250">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">OpenCossan: An Efficient Open Tool for Dealing with Epistemic and Aleatory Uncertainties</h3>
          <h4 style="color:gray;"> Patelli, E.,  Broggi, M.,  Angelis, M.D.,  Beer, M., </h4>
          <h4 style="color:blue;">2014</h4>
          <h4 style="color:green;">Vulnerability, Uncertainty, and Risk: Quantification, Mitigation, and Management - Proceedings of the 2nd International Conference on Vulnerability and Risk Analysis and Management, ICVRAM 2014 and the 6th International Symposium on Uncertainty Modeling and Analysis, ISUMA 2014</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1061/9780784413609.258">10.1061/9780784413609.258</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In this work, an integrated computational framework for uncertainty quantification and management is presented. Dealing with uncertainty might lead to impractical computational costs especially for detailed models. Hence, it is of paramount importance the availability of efficient numerical methods in order to reduce the computational costs of non-deterministic analyses by implementing the most efficient algorithms and taking advantages of the high performance computing. The computational framework OpenCossan is able to deal with different representation of uncertainty such as random variables, interval, distributional and free p-boxes. A wide range of engineering and scientific problems can be solved by the proposed computational framework thanks to its modular design. An application to a real case multidisciplinary optimization problem involving aleatory and epistemic variables is presented to show the flexibility and the power and the applicability of the software. © 2014 American Society of Civil Engineers.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933506353&amp;doi=10.1061%2f9780784413609.258&amp;partnerID=40&amp;md5=d524342c5d3234c3febf121d0a824ee7">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Line sampling for assessing structural reliability with imprecise failure probabilities</h3>
          <h4 style="color:gray;"> De Angelis, M.,  Patelli, E.,  Beer, M., </h4>
          <h4 style="color:blue;">2014</h4>
          <h4 style="color:green;">Vulnerability, Uncertainty, and Risk: Quantification, Mitigation, and Management - Proceedings of the 2nd International Conference on Vulnerability and Risk Analysis and Management, ICVRAM 2014 and the 6th International Symposium on Uncertainty Modeling and Analysis, ISUMA 2014</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1061/9780784413609.093">10.1061/9780784413609.093</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In this paper, a novel implementation of the Line Sampling method for computing imprecise probabilities is presented. The model of uncertainty is generalised to include both aleatory and epistemic uncertainties which comprise gaps of knowledge and scarcity of data. The proposed generalised uncertainty model allows for sets of probability distribution functions - also known as credal sets - and sets of bounded variables. The proposed implementation, based on the Adaptive Line Sampling algorithm, not only makes the computation of single probabilities a lot faster but, most importantly, eases the search for lower and upper bounds of the failure probability. © 2014 American Society of Civil Engineers.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933529698&amp;doi=10.1061%2f9780784413609.093&amp;partnerID=40&amp;md5=62637a92be60e022495f994515f5ccd3">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Towards Efficient Ways of Estimating Failure Probability of Mechanical Structures under Interval Uncertainty</h3>
          <h4 style="color:gray;"> Beer, M.,  De Angelis, M.,  Kreinovich, V., </h4>
          <h4 style="color:blue;">2014</h4>
          <h4 style="color:green;">Vulnerability, Uncertainty, and Risk: Quantification, Mitigation, and Management - Proceedings of the 2nd International Conference on Vulnerability and Risk Analysis and Management, ICVRAM 2014 and the 6th International Symposium on Uncertainty Modeling and Analysis, ISUMA 2014</h4>
          <p style="color:gray">doi: <a href="https://doi.org/10.1061/9780784413609.033">10.1061/9780784413609.033</a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: Whether a structure is stable depends on the values of the parameters = (1, n) which describe the structure and its environment. Usually, we know the limit function g() describing stability: a structure is stable if and only if g0. If we also know the probability distribution on the set of all possible combinations , then we can estimate the failure probability P. In practice, we often know that the probability distribution belongs to the known family of distributions (e.g., normal), but we only know the approximate values pi of the parameters pi characterizing the actual distribution. Similarly, we know the family of possible limit functions, but we have only approximate estimates of the parameters corresponding to the actual limit function. In many such situations, we know the accuracy of the corresponding approximations; i.e., we know an upper bound - for which pi-pi. In this case, the only information that we have about the actual (unknown) values of the corresponding parameters p is that p is in the interval [p-, pi +]. Different values pi from the corresponding intervals lead, in general, to different values of the failure probability P. So, under such interval uncertainty, it is desirable to find the range [P, P-]. In this paper, we describe efficient algorithms for computing this range. We also show how to take into account the model inaccuracy, i.e., the fact that the finite-parametric models of the distribution and of the limit function provide only an approximate descriptions of the actual ones. © 2014 American Society of Civil Engineers.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933558023&amp;doi=10.1061%2f9780784413609.033&amp;partnerID=40&amp;md5=423a6787ac202f650cec9c53545caf27">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Line sampling approach for extreme case analysis in presence of aleatory and epistemic uncertainties</h3>
          <h4 style="color:gray;"> Patelli, E.,  De Angelis, M., </h4>
          <h4 style="color:blue;">2015</h4>
          <h4 style="color:green;">Safety and Reliability of Complex Engineered Systems - Proceedings of the 25th European Safety and Reliability Conference, ESREL 2015</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In many real world situations, engineers are not able to perfectly model or predict the performance of systems or components due to the quality and amount of information available and the presence of unavoidable uncertainty. Despite the different levels of uncertainty and imprecision, it is still necessary to be able to propagate the uncertainty through the model and quantify the risk. In particular, decision makers need to know the confidence associated with the methodology adopted to model the uncertainty and avoid wrong decisions due to artificial restrictions introduced by the modelling. Hence, a generalized uncertainty quantification tool for dealing with different representation of the uncertainty is needed. This paper presents a generally applicable and efficient strategy to perform extreme case analysis where only limited amount of information is available. This is achieved defining probability boxes, intervals and fuzzy variables to represent the epistemic uncertainty and assessing the reliability computing the failure probability bounds by means of efficient advanced Monte Carlo sampling based on Line Sampling. A novel strategy has been developed to estimate the bounds of the failure probability and to identify the input distributions that best fit the distributions of the extreme realizations. © 2015 Taylor &amp; Francis Group, London.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959010492&amp;partnerID=40&amp;md5=66b7763fa4f5d7e5d8cddabe20a5c179">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Robust design of inspection schedules by means of probability boxes for structural systems prone to damage accumulation</h3>
          <h4 style="color:gray;"> De Angelis, M.,  Patelli, E.,  Beer, M., </h4>
          <h4 style="color:blue;">2015</h4>
          <h4 style="color:green;">Safety and Reliability of Complex Engineered Systems - Proceedings of the 25th European Safety and Reliability Conference, ESREL 2015</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: The design of inspection schedules is a complex optimization problem that requires the reliability to be assessed. The solution to this problem can be found balancing the costs associated to inspection/repair activities against the benefits related to the faultless operation of the infrastructure. The optimization aims at minimizing the total cost, obtained as the combination of maintenance and failure costs, by tuning some design parameters, such as the number, time and quality of inspections. The reliability is assessed making use of probability boxes, i.e. by accounting for both variability and imprecision. The use of probability boxes relaxes the assumption of exact input probability distributions, which is always too strong given that these distributions are very often estimated within a degree of confidence, or elicited from a finite set of experimental data. The optimization problem is formulated as a time-dependent reliability-based optimization problem, where both objective and constraint functions require the evaluation of upper and lower reliability bounds. The solution to this problem represents a real technological challenge, as the reliability assessment by means of p-boxes is a computationally intensive task, which may take up to few days to be completed on last generation processors. In this paper, an efficient and generally applicable numerical technique, which is capable of producing a solution in a very short amount of time (≤1 hour), is proposed. The technique combines a forced Monte Carlo simulation method with an optimization strategy, which makes the interval reliability assessment particularly efficient. The efficiency and accuracy of the proposed technique is shown by means of a literature example involving a fatigue-prone weld in a bridge girder. © 2015 Taylor &amp; Francis Group, London.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959010803&amp;partnerID=40&amp;md5=40c8ba98abd77c9592c2ed5b40091180">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">An open approach to educational resource development, with a specific example from structural engineering</h3>
          <h4 style="color:gray;"> Comerford, L.,  DeAngelis, M.,  Mannis, A.,  Beer, M.,  Kougioumtzoglou, I., </h4>
          <h4 style="color:blue;">2014</h4>
          <h4 style="color:green;">SEFI Annual Conference 2014</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: </p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939188828&amp;partnerID=40&amp;md5=e964ade43cd44bfcee58e83075ed2c8c">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">An integrated and efficient numerical framework for uncertainty quantification: Application to the NASA Langley multidisciplinary Uncertainty Quantification Challenge</h3>
          <h4 style="color:gray;"> Patelli, E.,  Broggi, M.,  De Angelis, M.,  Alvarez, D.A., </h4>
          <h4 style="color:blue;">2014</h4>
          <h4 style="color:green;">16th AIAA Non-Deterministic Approaches Conference</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In this work, an integrated framework to deal with scarce data, aleatory and epistemic uncertainties is presented. Generally, dealing with the uncertainty requires the availability of efficient and scalable computational tools. For this reason, the proposed strategies have been implemented in an open general purpose computational framework for uncertainty quantification and management that allows for a significant reduction of the computational time required by adopting efficient techniques for uncertainty quantification and resorting to the computational power of a cluster computing. The proposed framework has been adopted to solve the NASA Langley multidisciplinary uncertainty quantification challenge. All the five subproblems have been tacked, i.e. uncertainty characterization, sensitivity analysis, uncertainty quantification, extreme case analysis and robust design. All the subproblems have been solved using different approaches based on different hypotheses and assumption in order to cross-validate the results and showing the exibility and potentiality and computational framework.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84894504361&amp;partnerID=40&amp;md5=3c12872faf043d3973d6753c19bf040f">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">Interval solution and robust validation of uncertain elastic beams</h3>
          <h4 style="color:gray;"> Gabriele, S.,  Valente, C.,  De Angelis, M., </h4>
          <h4 style="color:blue;">2013</h4>
          <h4 style="color:green;">Safety, Reliability, Risk and Life-Cycle Performance of Structures and Infrastructures - Proceedings of the 11th International Conference on Structural Safety and Reliability, ICOSSAR 2013</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In the field of structural mechanics the notion of uncertainty is employed in several contexts such as modelling, analysis, experiments, and reliability. When dealing with problems involved with uncertainty the model of the system should include an appropriate representation of the uncertain quantities. Among different formulations capable of representing uncertainties, certainly interval analysis promises to be very effective since it is not required to handle distributions as where probability is concerned. In this work the attention will be focused on the so-called direct problem where the mechanical model and the amount of uncertainty in the parameters are a priori given and the goal is to evaluate how and to what extent the uncertainty propagates and influences the response of the system. In this context, the uncertainty may come from the scarce knowledge about the materials, geometry and boundary conditions that constitute the structural model. An example of this is the uncertainty in loading, which intensity, area and location contribute to shape the mathematical equations that describe the problem. The purpose of the paper is to go through the use of the interval formulation as alternative to the probability formulation in the study of systems embodying uncertain parameters. Sample problems concerning the statics of beams will be addressed and the interval solution will be discussed and compared to analytic or Monte Carlo probability solutions. The effectiveness of the presented approach is demonstrated by means of a real case example, where a set of precast concrete beams undertaking static tests is analysed. © 2013 Taylor &amp; Francis Group, London.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892427019&amp;partnerID=40&amp;md5=8a5ea03bdffddf03fadd6586bf6e4462">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">An efficient strategy for computing interval expectations of risk</h3>
          <h4 style="color:gray;"> De Angelis, M.,  Patelli, E.,  Beer, M., </h4>
          <h4 style="color:blue;">2013</h4>
          <h4 style="color:green;">Safety, Reliability, Risk and Life-Cycle Performance of Structures and Infrastructures - Proceedings of the 11th International Conference on Structural Safety and Reliability, ICOSSAR 2013</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: In order to minimize risks it is of paramount importance to take into account the effects of uncertainties from the design stage. In fact, the knowledge about the behaviour of complex systems and future conditions is always incomplete. Risk-based optimization is a powerful and well-recognized tool for identification of the optimal (robust) design with a systematic consideration of uncertainty. More specifically, this approach looks for the best design solution, whilst minimizing the risk, thus considering the effects of uncertainties giving a measure of safety levels. However, traditional optimization procedures come out with a punctual (single) optimum that rarely can be translated in engineering solutions, leaving little or no room for manufacturing and operating tolerances. The optimization shall be given an even more rational connotation for treating the uncertainties that comprises set-wise quantities. Solution is found by means of interval analysis even if it introduces further computational costs that are herein addressed developing tailored numerical strategies. In this paper an efficient method that allows to break down the computational costs of risk and uncertainty analyses considering intervals is presented. The method, implemented in an open source computational framework, is based on a very efficient Monte Carlo technique. Numerical results are delivered showing the applicability and efficiency of the proposed approach. © 2013 Taylor &amp; Francis Group, London.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892410847&amp;partnerID=40&amp;md5=0592c4725c7dfef42545dae178b99d89">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
        <div style="background:#e0e0eb; width:80%">
          <p style="color:gray;">Conference Paper</p>
          <h3 style="text-align:center;">An open computational framework for reliability based optimization</h3>
          <h4 style="color:gray;"> Patelli, E.,  De Angelis, M., </h4>
          <h4 style="color:blue;">2012</h4>
          <h4 style="color:green;">Civil-Comp Proceedings</h4>
          <p style="color:gray">doi: <a href="https://doi.org/"></a></p>
          <p style="color:gray; font-size:10pt"> <u>Abstract</u>: This paper presents an open computational framework for reliability based. The framework has been designed to provide the maximum flexibility allowing the state of the art in reliability analysis (e.g. adopting advanced Monte Carlo methods) to be combined in the direct approach as well as in the construction of the different type of meta-models (e.g. response surface, artificial neural networks, kriging model and polynomial chaos, etc.). A set of widely used gradient-based and gradient-free optimization algorithms are also available for performing the optimization step as well as high performance computing capability. Numerical applications show the applicability and flexibility of the proposed framework for solving real-life problems. © Civil-Comp Press, 2012.</p>
          <p style="text-align:right;"><a href="https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893958628&amp;partnerID=40&amp;md5=50a26be56c504a50c751549b5c498917">[scopus]</a> | <a href="">[direct]</a></p>
        </div>
    
  </body>
</html>
